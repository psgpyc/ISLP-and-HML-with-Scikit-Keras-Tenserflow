{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8250c84-31aa-42a0-9960-a0eec9d0c977",
   "metadata": {},
   "source": [
    "The least squares is a mathematical optimising technique used to find a best-fit solution to an over determined system (i.e more equations than the unknown) by minimising the sum of the squares of the residuals(the difference between the observed and predicted values). \n",
    "\n",
    "**What is a over-determined system?**\n",
    "\n",
    "Suppose we have two unknowns $( x \\  \\text{and} \\ y)$ and the following equations,\n",
    "\n",
    "$1. \\ x + y = 10   $  \n",
    "$2.\t \\ 2x + 3y = 20   $  \n",
    "$3. \\ x - y = 2 $    \n",
    "\n",
    "If, we try to solve for $x$ and $y$, we might find that there is no pair $(x, y)$ that satisfies all three exactly because the conditions might be conflicting.\n",
    "\n",
    "\n",
    "Why Does This Happen?  \n",
    "\n",
    "In an overdetermined system:  \n",
    "\t•\tRedundancy: Sometimes extra equations are just redundant. For example, if the third equation were just a combination of the first two, then all three could still be satisfied.  \n",
    "\t•\tConflict: More often, however, the extra equation introduces a conflict. This is especially true when the data or measurements (in practical problems) are imprecise or noisy.   There may not be a perfect solution that meets every condition exactly.  \n",
    "\n",
    "**When it is impossible to satisfy all equations exactly, we use methjods like least squares**\n",
    "\n",
    "The least squares finds approach finds the solution that minimises the overall \"error\" instead of getting an exact solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d09953-0bef-405e-91df-0c9ba45b0d76",
   "metadata": {},
   "source": [
    "### Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c139bb-fc23-49cc-b57a-0be7cd947e7e",
   "metadata": {},
   "source": [
    "The normal equations are a set of equations used to solve the least square problem. \n",
    "\n",
    "Suppose we have a system of linear equations represented in matix form, \n",
    "\n",
    "$Ax = b$,  \n",
    "\n",
    "where:\n",
    "\n",
    "- $A$ is an $m \\times n$ matrix,\n",
    "- $x$ is an $n$-dimentional vectors of unknows,\n",
    "- $b$ is an $n$-dimentional vectors of the observed values.\n",
    "\n",
    "In many cases, espicially when we have an over determined system, there might not be an exact solution of $x$ that satisfies $Ax = b$. Instead, we seek an $x$ that minimizes the squared error.\n",
    "\n",
    "\n",
    "$$ \\min_{x} \\| Ax - b \\|^2$$\n",
    "\n",
    "where the norm $\\| \\cdot \\|$ is usually the Euclidean norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21631c6f-7f31-4337-983e-8cb1e07c518e",
   "metadata": {},
   "source": [
    "**Derivation of the Normal Equations**\n",
    "\n",
    "To find the $x$ that minimizes the error, consider the function:\n",
    "\n",
    "\n",
    "$f(x) = \\| Ax - b \\|^2.$\n",
    "\n",
    "\n",
    "This can be written as:\n",
    "\n",
    "\n",
    "$f(x) = (Ax - b)^T (Ax - b).$\n",
    "\n",
    "\n",
    "Expanding the expression, we get:\n",
    "\n",
    "\n",
    "$f(x) = x^T A^T A x - 2b^T A x + b^T b.$\n",
    "\n",
    "\n",
    "To minimize f(x), we take the gradient with respect to x and set it equal to zero:\n",
    "\n",
    "\n",
    "$\\nabla_x f(x) = 2A^T A x - 2A^T b = 0.$\n",
    "\n",
    "\n",
    "Dividing through by 2 gives:\n",
    "\n",
    "\n",
    "$A^T A x = A^T b.$\n",
    "\n",
    "\n",
    "This is the normal equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb5f3d-490b-42fb-8dfa-1f28be65b682",
   "metadata": {},
   "source": [
    "**Solving the Normal Equations**\n",
    "\n",
    "When $A^T A$ is Invertible\n",
    "\n",
    "If A has full column rank (i.e., the columns of A are linearly independent), then $A^T A$ is invertible. In that case, you can solve for $x$ directly:\n",
    "\n",
    "\n",
    "$x = (A^T A)^{-1} A^T b.$\n",
    "\n",
    "\n",
    "This $x$ is the unique solution that minimizes the squared error $\\| Ax - b \\|^2.$\n",
    "\n",
    "When $A^T A$ is Not Invertible\n",
    "\n",
    "If A does not have full column rank, then $A^T A$ is singular (noninvertible), and the least squares solution is not unique. In such cases, methods like the Moore-Penrose pseudoinverse are used to compute a solution with additional properties (such as the minimum norm solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ec7eb-ba56-48cb-966e-2739c8889ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
