{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb8fc7b-dc3b-4066-a5ae-86dbf2f8f57e",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "Support Vector Machine (SVM) is a supervised machine learning algorithm used for both classification and regression tasks. However, it's mostly popular for classification problems.\n",
    "\n",
    "**Goal:** Find the best boundary (called a hyperplane) that separates different classes of data.\n",
    "\n",
    "**Key Idea:** Maximise the distance (or margin) between the boundary and the nearest data points from each class.\n",
    "\n",
    "\n",
    "### **What is a Hyperplane?**\n",
    "\n",
    "A hyperplane is the decision boundary that separates data points of different classes.\n",
    "\n",
    "In 2D: It’s a straight line.\n",
    "\n",
    "In 3D: It’s a flat plane.\n",
    "\n",
    "In higher dimensions: It’s called a hyperplane.\n",
    "\n",
    "\n",
    "### **What is a Margin?**\n",
    "\n",
    "The margin is the distance between the hyperplane and the closest data points from each class. These closest data points are called ***support vectors.***\n",
    "\n",
    "**Hard Margin SVM:**\n",
    "\n",
    "- No data points can be inside the margin.\n",
    "\n",
    "- Perfect separation required (works only for linearly separable data).\n",
    "\n",
    "- Problem: Sensitive to outliers and noise.\n",
    "\n",
    "**Soft Margin SVM:**\n",
    "\n",
    "- Allows some data points to be inside the margin or even misclassified.\n",
    "\n",
    "- Introduces a regularisation parameter  to control the trade-off between margin size and misclassification.\n",
    "\n",
    "- Advantage: More flexible, handles noisy data better.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/SVM Hyperplane with Margins and Normal Vector.png\" width=\"800\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80870967-f2f2-4c8c-9296-a3229c4f9a6e",
   "metadata": {},
   "source": [
    "## Support Vectors\n",
    "\n",
    "In Support Vector Machines (SVM), support vectors are the data points that lie closest to the decision boundary (also called the hyperplane).  \n",
    "\n",
    "These points are crucial because they:  \n",
    "\t1.\tDefine the Optimal Hyperplane: The SVM algorithm tries to find a hyperplane that best separates the classes with the maximum margin. The support vectors are the points that the margin “touches” on both sides.  \n",
    "\t2.\tMaximise the Margin: The distance between the hyperplane and the support vectors is the margin. SVM aims to maximise this margin for better generalisation.  \n",
    "\t3.\tImpact Model Performance: Removing or changing support vectors can shift the decision boundary, whereas non-support vectors don’t directly affect it.  \n",
    "\n",
    "Here’s a quick visual explanation:  \n",
    "\t•\tHyperplane: The decision boundary that separates classes.\n",
    "\t•\tMargin: The gap between the hyperplane and the support vectors.\n",
    "\t•\tSupport Vectors: The data points sitting right on the edge of the margin.\n",
    "\n",
    "\n",
    "<img src=\"./images/decision_boundary.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3310431a-9af4-4761-b0aa-894d2476291e",
   "metadata": {},
   "source": [
    "**Hard Margin Classification: What It Means**\n",
    "\n",
    "In hard margin SVM, the rules are:  \n",
    "\t•\tNo data points are allowed between the decision boundary and the support vectors.  \n",
    "\t•\tNo misclassifications are allowed—every data point must be correctly classified.\n",
    "\n",
    "This works well if the data is perfectly linearly separable, but real-world data rarely is.\n",
    "\n",
    "The Problem with Hard Margins  \n",
    "\n",
    "1.\tNot Flexible:    \n",
    "\n",
    "    - Since the model tries to perfectly separate the data, even slight overlaps or noise can break the model.  \n",
    "    - The hyperplane becomes too sensitive, adjusting unnecessarily to tiny variations.   \n",
    "    \n",
    "2.\tReduced Margin (Less Generalisation):  \n",
    "\n",
    "    - Outliers or noisy data points can pull the decision boundary closer, reducing the margin.  \n",
    "    - This leads to overfitting, where the model memorises the training data instead of learning the general pattern. \n",
    "     \n",
    "3.\tOutliers Cause Big Problems:  \n",
    "\n",
    "    - One outlier can completely change the position of the hyperplane because hard margin SVM has no tolerance for misclassification.  \n",
    "    - This makes the model fragile.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27f07c-2748-4d79-9c17-3565f2b30533",
   "metadata": {},
   "source": [
    "**Soft Margin: A More Flexible Approach**\n",
    "\n",
    "To solve these problems, we use soft margin SVM. Here:  \n",
    "\n",
    "1. The model allows some data points to be within the margin or even misclassified.  \n",
    "2. It introduces a regularisation parameter  C :  \n",
    "\n",
    "    - High  C  = Less tolerance for misclassification (similar to hard margin).  \n",
    "    - Low  C  = More tolerance, allowing better flexibility and generalisation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8bf39-f929-428d-a58e-4ba366089925",
   "metadata": {},
   "source": [
    "<img src=\"./images/Large Margin (Soft Margin SVM).png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04f496-6ad0-4178-93d4-eafaaaeb85a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
