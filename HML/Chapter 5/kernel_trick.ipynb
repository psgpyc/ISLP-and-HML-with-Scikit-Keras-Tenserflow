{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c885091d-ca22-49d8-8c7a-8198568fded5",
   "metadata": {},
   "source": [
    "# Kernel Trick: A Mathematical Explanation\n",
    "\n",
    "The kernel trick allows us to implicitly compute inner products in a high-dimensional feature space without explicitly mapping the data into that space. This is particularly useful when the mapping is computationally expensive or even infinite-dimensional.\n",
    "\n",
    "## General Idea\n",
    "\n",
    "Suppose we have a mapping\n",
    "\n",
    "$$\n",
    "\\phi: \\mathbb{R}^d \\to \\mathcal{F},\n",
    "$$\n",
    "\n",
    "which takes an input vector $\\mathbf{x} \\in \\mathbb{R}^d$ and maps it to a (possibly high-dimensional) feature space $\\mathcal{F}$. Many algorithms (such as Support Vector Machines) only require the inner product between two mapped vectors, $\\phi(\\mathbf{x})$ and $\\phi(\\mathbf{y})$:\n",
    "\n",
    "$$\n",
    "\\langle \\phi(\\mathbf{x}), \\phi(\\mathbf{y}) \\rangle.\n",
    "$$\n",
    "\n",
    "If we can define a kernel function $k$ such that\n",
    "\n",
    "$$\n",
    "k(\\mathbf{x}, \\mathbf{y}) = \\langle \\phi(\\mathbf{x}), \\phi(\\mathbf{y}) \\rangle,\n",
    "$$\n",
    "\n",
    "then we can work directly with $k(\\mathbf{x}, \\mathbf{y})$ without ever computing $\\phi(\\mathbf{x})$ and $\\phi(\\mathbf{y})$ explicitly.\n",
    "\n",
    "## The Second-Degree Polynomial Example\n",
    "\n",
    "Consider a 2-dimensional input vector:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = (x_1, x_2).\n",
    "$$\n",
    "\n",
    "A common choice for a second-degree polynomial mapping is:\n",
    "\n",
    "$$\n",
    "\\phi(x_1, x_2) = \\begin{pmatrix}\n",
    "1 \\\\\n",
    "\\sqrt{2}\\, x_1 \\\\\n",
    "\\sqrt{2}\\, x_2 \\\\\n",
    "x_1^2 \\\\\n",
    "\\sqrt{2}\\, x_1 x_2 \\\\\n",
    "x_2^2\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "*Note:* The scaling factors (e.g., $\\sqrt{2}$) are chosen so that the dot product in the feature space yields a neat polynomial expansion.\n",
    "\n",
    "For two points $\\mathbf{x} = (x_1, x_2)$ and $\\mathbf{y} = (y_1, y_2)$, the inner product in the feature space is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle \\phi(\\mathbf{x}), \\phi(\\mathbf{y}) \\rangle &= 1\\cdot1 + (\\sqrt{2}\\, x_1)(\\sqrt{2}\\, y_1) + (\\sqrt{2}\\, x_2)(\\sqrt{2}\\, y_2) \\\\\n",
    "&\\quad + x_1^2 y_1^2 + (\\sqrt{2}\\, x_1 x_2)(\\sqrt{2}\\, y_1 y_2) + x_2^2 y_2^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Simplify each term:\n",
    "\n",
    "- $1 \\cdot 1 = 1$\n",
    "- $(\\sqrt{2}\\, x_1)(\\sqrt{2}\\, y_1) = 2\\, x_1 y_1$\n",
    "- $(\\sqrt{2}\\, x_2)(\\sqrt{2}\\, y_2) = 2\\, x_2 y_2$\n",
    "- $(\\sqrt{2}\\, x_1 x_2)(\\sqrt{2}\\, y_1 y_2) = 2\\, x_1 x_2\\, y_1 y_2$\n",
    "\n",
    "Thus, the dot product becomes:\n",
    "\n",
    "$$\n",
    "\\langle \\phi(\\mathbf{x}), \\phi(\\mathbf{y}) \\rangle = 1 + 2\\,x_1 y_1 + 2\\,x_2 y_2 + x_1^2 y_1^2 + 2\\,x_1 x_2\\, y_1 y_2 + x_2^2 y_2^2.\n",
    "$$\n",
    "\n",
    "Now, consider the expansion of the kernel function:\n",
    "\n",
    "$$\n",
    "k(\\mathbf{x}, \\mathbf{y}) = \\big(1 + \\mathbf{x}^\\top \\mathbf{y}\\big)^2 = \\big(1 + x_1 y_1 + x_2 y_2\\big)^2.\n",
    "$$\n",
    "\n",
    "Expanding this, we have:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(1 + x_1 y_1 + x_2 y_2)^2 &= 1 + 2\\,x_1 y_1 + 2\\,x_2 y_2 \\\\\n",
    "&\\quad + (x_1 y_1)^2 + 2\\,x_1 y_1\\,x_2 y_2 + (x_2 y_2)^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Recognize that:\n",
    "\n",
    "$$\n",
    "(x_1 y_1)^2 = x_1^2 y_1^2 \\quad \\text{and} \\quad (x_2 y_2)^2 = x_2^2 y_2^2.\n",
    "$$\n",
    "\n",
    "Thus, we have:\n",
    "\n",
    "$$\n",
    "(1 + x_1 y_1 + x_2 y_2)^2 = 1 + 2\\,x_1 y_1 + 2\\,x_2 y_2 + x_1^2 y_1^2 + 2\\,x_1 x_2\\, y_1 y_2 + x_2^2 y_2^2.\n",
    "$$\n",
    "\n",
    "This expression is identical to the dot product computed in the feature space:\n",
    "\n",
    "$$\n",
    "\\langle \\phi(\\mathbf{x}), \\phi(\\mathbf{y}) \\rangle.\n",
    "$$\n",
    "\n",
    "## The Kernel Trick\n",
    "\n",
    "The key observation is that instead of explicitly computing $\\phi(\\mathbf{x})$ (which maps $\\mathbf{x}$ into a 6-dimensional space), we can compute the kernel function directly:\n",
    "\n",
    "$$\n",
    "k(\\mathbf{x}, \\mathbf{y}) = \\big(1 + \\mathbf{x}^\\top \\mathbf{y}\\big)^2.\n",
    "$$\n",
    "\n",
    "This computation is much simpler and avoids working in the higher-dimensional space explicitly.\n",
    "\n",
    "## Summary\n",
    "\n",
    "1. **Mapping:**\n",
    "\n",
    "   $$\n",
    "   \\phi(x_1, x_2) = \\begin{pmatrix}\n",
    "   1 \\\\\n",
    "   \\sqrt{2}\\, x_1 \\\\\n",
    "   \\sqrt{2}\\, x_2 \\\\\n",
    "   x_1^2 \\\\\n",
    "   \\sqrt{2}\\, x_1 x_2 \\\\\n",
    "   x_2^2\n",
    "   \\end{pmatrix}\n",
    "   $$\n",
    "\n",
    "2. **Inner Product in Feature Space:**\n",
    "\n",
    "   $$\n",
    "   \\langle \\phi(\\mathbf{x}), \\phi(\\mathbf{y}) \\rangle = 1 + 2\\,x_1 y_1 + 2\\,x_2 y_2 + x_1^2 y_1^2 + 2\\,x_1 x_2\\, y_1 y_2 + x_2^2 y_2^2.\n",
    "   $$\n",
    "\n",
    "3. **Kernel Function:**\n",
    "\n",
    "   $$\n",
    "   k(\\mathbf{x}, \\mathbf{y}) = \\big(1 + \\mathbf{x}^\\top \\mathbf{y}\\big)^2.\n",
    "   $$\n",
    "\n",
    "4. **Kernel Trick:**\n",
    "\n",
    "   Instead of computing $\\phi(\\mathbf{x})$ and then taking the dot product, we directly compute $k(\\mathbf{x}, \\mathbf{y})$, which is much more efficient.\n",
    "\n",
    "By using the kernel trick, algorithms such as Support Vector Machines (SVMs) can work in a high-dimensional feature space without explicitly mapping the data, enabling efficient computation and the ability to capture complex, non-linear relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486532b-63c8-4bd8-97d3-91ef0d88dced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
