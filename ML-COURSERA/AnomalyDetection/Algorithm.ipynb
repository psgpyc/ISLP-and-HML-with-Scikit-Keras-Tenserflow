{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b3d5a0-0b2d-4d33-8b3e-1d5b19146828",
   "metadata": {},
   "source": [
    "## Density Estimation\n",
    "\n",
    "## Overview \n",
    "\n",
    "Density estimation is a technique used to estimate the probability distribution of a dataset. It involves estimating the underlying distribution function from a set of data points, which may or may not come from a known distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12924e84-9b88-4a2f-ba33-1a645f1deffe",
   "metadata": {},
   "source": [
    "Consider out training set: ${{ \\vec x^{(1)}, \\vec x^{(2)},.... ,\\vec x^{(m)}}}$  \n",
    "\n",
    "Each examples $\\vec x^{(i)}$ has $n$ features.\n",
    "\n",
    "Our probability function will be, \n",
    "\n",
    "$p({\\vec x}) = p(x_1; \\mu_1, \\sigma_1^2) *  p(x_2; \\mu_2, \\sigma_2^2) * \\cdot \\cdot \\cdot * p(x_n; \\mu_n, \\sigma_n^2)   $\n",
    "\n",
    "\n",
    "$= \\prod_{j=1}^n p(x_j; \\mu_j, \\sigma_j^2)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2287a73-3221-4388-b949-f140e3de5b7f",
   "metadata": {},
   "source": [
    "**Defination found in Books >>>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2cae63-2951-4762-84b5-aa124d8a99f2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Parametric Density Estimation\n",
    "\n",
    "In **parametric density estimation**, we assume that the data follows a certain distribution. For example, if we assume the data follows a **normal distribution**, we estimate the parameters (mean $\\mu$ and variance $\\sigma^2$) that define that distribution. The probability density function (PDF) for a normal distribution is given by:\n",
    "\n",
    "$$\n",
    "f(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $x$ is a data point.\n",
    "- $\\mu$ is the mean.\n",
    "- $\\sigma^2$ is the variance.\n",
    "\n",
    "The parameters $\\mu$ and $\\sigma^2$ can be estimated from the data using methods like **maximum likelihood estimation (MLE)**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1c526-c716-434a-8e1b-524bcc6af04d",
   "metadata": {},
   "source": [
    "## The Final Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474a38e-1f30-45e2-9c1f-fa4453e38bee",
   "metadata": {},
   "source": [
    "1. Choose $n$ features $x_i$ that is indicative if anoamlous examples.\n",
    "2. Fit parameters $\\mu_1, \\mu_2, .....,\\mu_n, \\sigma_1, ......,\\sigma_n$  \n",
    "   where,\n",
    "   $\\mu_j = \\frac{1}{m}\\sum_{i=1}^m x_j^{(i)}$  \n",
    "   $\\sigma_j^2 = \\frac{1}{m}\\sum_{i=1}^m (x_j^{(i)} - \\mu_j)^2$\n",
    "\n",
    "3. Given new examples $x$, compute $p(x)$  \n",
    "   $p(x)$ = $= \\prod_{j=1}^n p(x_j; \\mu_j, \\sigma_j^2)$ = $\\prod_{j=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$\n",
    "\n",
    "4. Anomaly if $p(x) < \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f563f-7bd2-4b78-af79-c0451606535a",
   "metadata": {},
   "source": [
    "## The real-number evaluation\n",
    "\n",
    "When we are developing a learning algorithm, say choosing different features or trying different values of the parameters like $\\epsilon$, making decisions about whether or not to change a feature in a certain way or to increase or decrease epsilon or other parameters, making those decisions is much easier if you have a way of evaluating the learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e388acf-8f54-431e-8804-8872ed34ad49",
   "metadata": {},
   "source": [
    "*Real number evaluation* means having a method to evaluate the system’s performance during development. For example, by adjusting parameters like *epsilon* or changing features, you can evaluate whether the algorithm’s performance has improved. This makes it easier to make quick adjustments.\n",
    "\n",
    "- In anomaly detection, even though most data is unlabeled, we can use a small number of labeled anomalies (e.g., data points with `y=1` indicating anomalies) and normal examples (`y=0`).\n",
    "\n",
    "## Training and Evaluation Setup\n",
    "1. **Training Set:** You train the anomaly detection algorithm using mostly normal data (`y=0`). This is an unsupervised learning algorithm.\n",
    "2. **Cross-Validation and Test Sets:** You create a cross-validation set and a test set, both of which should have a mix of normal and anomalous examples.\n",
    "   - **Example:** \n",
    "     - Training set: 6,000 normal engines\n",
    "     - Cross-validation set: 2,000 normal engines + 10 anomalies\n",
    "     - Test set: 2,000 normal engines + 10 anomalies\n",
    "   - The cross-validation set helps you tune parameters (like epsilon) to avoid overfitting.\n",
    "\n",
    "## Tuning Parameters with Cross-Validation\n",
    "- After training the model, you evaluate it on the cross-validation set to see how well it detects anomalies.\n",
    "- By adjusting the *epsilon* parameter, you can fine-tune the system. A higher epsilon makes the model stricter, while a lower epsilon makes it more lenient.\n",
    "\n",
    "## Handling Imbalanced Data\n",
    "- Anomaly detection usually involves imbalanced datasets, where anomalies (`y=1`) are much fewer than normal examples (`y=0`).\n",
    "- **Alternative Metrics:** Traditional accuracy metrics might not be suitable. Instead, use:\n",
    "  - **Precision:** The proportion of true positives among all flagged anomalies.\n",
    "  - **Recall:** The proportion of true positives among all actual anomalies.\n",
    "  - **F1 Score:** The harmonic mean of precision and recall, balancing the two metrics.\n",
    "\n",
    "## Alternative Approach for Small Datasets\n",
    "- If the dataset is small, especially in terms of anomalies, you might not have enough data to split into a training set, cross-validation set, and a separate test set.\n",
    "- In this case, use just the training set and cross-validation set.\n",
    "   - Training set: 6,000 normal engines\n",
    "   - Cross-validation set: 4,000 normal engines + all anomalies\n",
    "   - The downside is that you won’t have a separate test set to evaluate how well your model will generalize to future data, which may increase the risk of overfitting.\n",
    "\n",
    "## Model Evaluation Process\n",
    "- After training on the training set, compute the probability of each example in the cross-validation or test set being an anomaly using the model.\n",
    "- If the probability is less than epsilon, it’s flagged as anomalous (`y=1`), and if it’s greater than or equal to epsilon, it’s considered normal (`y=0`).\n",
    "- You then compare the predictions with actual labels to evaluate the model's performance.\n",
    "\n",
    "## Why Use Unsupervised Learning for Anomaly Detection?\n",
    "- Even if you have some labeled anomalies, anomaly detection typically uses an unsupervised learning algorithm. This is because anomalies are rare, and there may not be enough labeled examples to train a supervised model.\n",
    "- The approach mixes unsupervised and supervised techniques, where you fine-tune an unsupervised algorithm using a small number of labeled anomalies.\n",
    "\n",
    "## Conclusion\n",
    "By combining unsupervised learning with a small number of labeled anomalies, this method allows for efficient model development. It ensures that the system can be quickly tuned and evaluated for real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b0549-22bf-4529-91aa-0d40a3ab5abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
