{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5ad167-edb7-4fe4-9249-c2afa260937a",
   "metadata": {},
   "source": [
    "## State Action Value Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4a99e-d04d-42d9-bab6-e3af2432708a",
   "metadata": {},
   "source": [
    "$Q(s,a)$ = Return if you  \n",
    "             - start in state $s$  \n",
    "                - take action $a$ (once)  \n",
    "                - then behave optimally after that  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d27f8b-afae-499f-84ec-3044948695ca",
   "metadata": {},
   "source": [
    "In the mars rover example, if the discount factor is $0.5$, \n",
    "the the policy is to go left except for state 5. In state 5 go right.\n",
    "\n",
    "In below example, if you compare the return for each state, the return for state 5 is greater for right. For the rest, the left is always greater.\n",
    "\n",
    "\n",
    "**As per the Q-function, we take a step and after that we behave optimally.** \n",
    "\n",
    "**So, if we are at state 2 and take a right step. The next steps will be to take the left until you reach the terminal state with the reward 100. This is because,the optimal policy when in state 2 is to go left**\n",
    "\n",
    "\n",
    "\n",
    "$Q(2, right)$ = $0 + 0.5 \\times 0 + 0.5^2 \\times 0 + 0.5^3 \\times 100 = 12.5$\n",
    "> Here, (state 2) -> right(state 3) return back to left(state 2) and keeps going left to terminal state because going left from state 3 is the optimal policy.\n",
    "\n",
    "$Q(2, left)$ = $0 + 0.5 \\times 100 = 50$\n",
    "> Here, it goes straight to the termianl state, as going left from state 2 is the optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832747d3-eb90-438d-837c-7906418ec79b",
   "metadata": {},
   "source": [
    "In the example above:\n",
    "<img src=\"./images/Qfunction.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29294855-9578-4723-92bd-c15d18eb87bb",
   "metadata": {},
   "source": [
    "For, $Q(4, left)$, if it takes left and keeps taking left after that(its the optimal step), \n",
    "The returns for each state in shown in the first example.\n",
    "\n",
    "Similarly, \n",
    "For, $Q(4, right)$, if it takes right. It reaches step 5. And for step 5, the optimal step is to keep taking righ to reach terminal right position.\n",
    "\n",
    "The returns for each state is:\n",
    "\n",
    "For State 4:  \n",
    "$Q(4, left)$ = $0 + 0.5 \\times 0 + 0.5^2 \\times 0 + 0.5^3 \\times 100 = 12.5$  \n",
    "  \n",
    "$Q(4, right)$ = $0 + 0.5 \\times 0 + 0.5^2 \\times 40 = 10$\n",
    "\n",
    "The best possible return from state 4 is $Q(4, left) = 12.5$ because it has higher return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139e6ff-15cd-4ed0-9cf3-cd91fec446b3",
   "metadata": {},
   "source": [
    "We can use the Q-Function to pick the action aswell, \n",
    "\n",
    "The best possible return from state $s$ is $ max:a\\ Q(s,a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17553426-eddc-4092-ad3b-d117a9c84c8b",
   "metadata": {},
   "source": [
    "**The best possible action in state $s$ is the action $a$ that gives $max:a \\ Q(s,a)$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084dbaf-3916-42f9-908e-e8146a7d5eca",
   "metadata": {},
   "source": [
    "## Take an action(left or right)\n",
    "## using the policy calculate $Q(s, a)$\n",
    "## Choose the action that maximises $Q(s,a)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c178c-5090-4b20-9f24-9b40f25f79c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
