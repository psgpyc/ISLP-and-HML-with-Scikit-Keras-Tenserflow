{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f3717bf-3426-4a99-833f-35e8471a9db0",
   "metadata": {},
   "source": [
    "# Logistic Regression with 10 Data Points: Detailed Example\n",
    "\n",
    "## Problem Setup\n",
    "\n",
    "We are predicting whether customers will purchase a product ($y = 1$) or not ($y = 0$) based on the number of emails theyâ€™ve read ($x$).\n",
    "\n",
    "### **Given Data**\n",
    "\n",
    "| Example ($i$) | Emails Read ($x^{(i)}$) | True Label ($y^{(i)}$) |\n",
    "|------------------|---------------------------|--------------------------|\n",
    "| 1                | 1                         | 0                        |\n",
    "| 2                | 2                         | 0                        |\n",
    "| 3                | 3                         | 0                        |\n",
    "| 4                | 4                         | 1                        |\n",
    "| 5                | 5                         | 1                        |\n",
    "| 6                | 6                         | 1                        |\n",
    "| 7                | 7                         | 1                        |\n",
    "| 8                | 8                         | 1                        |\n",
    "| 9                | 9                         | 1                        |\n",
    "| 10               | 10                        | 1                        |\n",
    "\n",
    "---\n",
    "\n",
    "## Model Parameters\n",
    "\n",
    "- Weight: $w = 0.5$\n",
    "- Bias: $b = -2.5$\n",
    "\n",
    "The predicted probability is calculated using the **sigmoid function**:\n",
    "\n",
    "$$\n",
    "f_{\\vec{w}, b}(\\vec{x}) = \\frac{1}{1 + e^{-(w \\cdot x + b)}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Calculation\n",
    "\n",
    "### Step 1: Compute Predicted Probabilities ($f_{\\vec{w}, b}(\\vec{x}^{(i)})$)\n",
    "\n",
    "We compute $z^{(i)} = w \\cdot x^{(i)} + b$ for each example, then pass $z^{(i)}$ through the sigmoid function:\n",
    "\n",
    "| Example ($i$) | $x^{(i)}$ | $z^{(i)} = w \\cdot x^{(i)} + b$ | $f_{\\vec{w}, b}(\\vec{x}^{(i)}) = \\frac{1}{1 + e^{-z^{(i)}}}$ |\n",
    "|------------------|-------------|----------------------------------|---------------------------------------------------------|\n",
    "| 1                | 1           | $0.5 \\cdot 1 - 2.5 = -2.0$      | $ \\frac{1}{1 + e^{2.0}} \\approx 0.119$               |\n",
    "| 2                | 2           | $0.5 \\cdot 2 - 2.5 = -1.5$      | $ \\frac{1}{1 + e^{1.5}} \\approx 0.182$               |\n",
    "| 3                | 3           | $0.5 \\cdot 3 - 2.5 = -1.0$      | $ \\frac{1}{1 + e^{1.0}} \\approx 0.269$               |\n",
    "| 4                | 4           | $0.5 \\cdot 4 - 2.5 = -0.5$      | $ \\frac{1}{1 + e^{0.5}} \\approx 0.378$               |\n",
    "| 5                | 5           | $0.5 \\cdot 5 - 2.5 = 0.0$       | $ \\frac{1}{1 + e^{0.0}} = 0.500$                     |\n",
    "| 6                | 6           | $0.5 \\cdot 6 - 2.5 = 0.5$       | $ \\frac{1}{1 + e^{-0.5}} \\approx 0.622$              |\n",
    "| 7                | 7           | $0.5 \\cdot 7 - 2.5 = 1.0$       | $ \\frac{1}{1 + e^{-1.0}} \\approx 0.731$              |\n",
    "| 8                | 8           | $0.5 \\cdot 8 - 2.5 = 1.5$       | $ \\frac{1}{1 + e^{-1.5}} \\approx 0.818$              |\n",
    "| 9                | 9           | $0.5 \\cdot 9 - 2.5 = 2.0$       | $ \\frac{1}{1 + e^{-2.0}} \\approx 0.881$              |\n",
    "| 10               | 10          | $0.5 \\cdot 10 - 2.5 = 2.5$      | $ \\frac{1}{1 + e^{-2.5}} \\approx 0.924$              |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Compute Log Loss for Each Example\n",
    "\n",
    "The log loss formula depends on the true label ($y^{(i)}$):\n",
    "\n",
    "$$\n",
    "L(f_{\\vec{w}, b}(\\vec{x}^{(i)}), y^{(i)}) =\n",
    "\\begin{cases}\n",
    "-\\log(f_{\\vec{w}, b}(\\vec{x}^{(i)})) & \\text{if } y^{(i)} = 1 \\\\\n",
    "-\\log(1 - f_{\\vec{w}, b}(\\vec{x}^{(i)})) & \\text{if } y^{(i)} = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "| Example ($i$) | $y^{(i)}$ | $f_{\\vec{w}, b}(\\vec{x}^{(i)})$ | Log Loss $L(f_{\\vec{w}, b}(\\vec{x}^{(i)}), y^{(i)})$    |\n",
    "|------------------|------------|----------------------------------|--------------------------------------------------------|\n",
    "| 1                | 0          | 0.119                            | $-\\log(1 - 0.119) \\approx 0.127$                     |\n",
    "| 2                | 0          | 0.182                            | $-\\log(1 - 0.182) \\approx 0.201$                     |\n",
    "| 3                | 0          | 0.269                            | $-\\log(1 - 0.269) \\approx 0.312$                     |\n",
    "| 4                | 1          | 0.378                            | $-\\log(0.378) \\approx 0.972$                         |\n",
    "| 5                | 1          | 0.500                            | $-\\log(0.500) \\approx 0.693$                         |\n",
    "| 6                | 1          | 0.622                            | $-\\log(0.622) \\approx 0.474$                         |\n",
    "| 7                | 1          | 0.731                            | $-\\log(0.731) \\approx 0.314$                         |\n",
    "| 8                | 1          | 0.818                            | $-\\log(0.818) \\approx 0.201$                         |\n",
    "| 9                | 1          | 0.881                            | $-\\log(0.881) \\approx 0.127$                         |\n",
    "| 10               | 1          | 0.924                            | $-\\log(0.924) \\approx 0.079$                         |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Compute Total Cost\n",
    "\n",
    "The total cost is the average of all log losses:\n",
    "\n",
    "$$\n",
    "J(\\vec{w}, b) = \\frac{1}{m} \\sum_{i=1}^m L(f_{\\vec{w}, b}(\\vec{x}^{(i)}), y^{(i)})\n",
    "$$\n",
    "\n",
    "- $m = 10$ (10 examples).\n",
    "- Sum of all losses:\n",
    "$$\n",
    "\\text{Sum} = 0.127 + 0.201 + 0.312 + 0.972 + 0.693 + 0.474 + 0.314 + 0.201 + 0.127 + 0.079 = 3.500\n",
    "$$\n",
    "\n",
    "The total cost:\n",
    "$$\n",
    "J(\\vec{w}, b) = \\frac{3.500}{10} = 0.350\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Final Results\n",
    "\n",
    "1. **Predicted Probabilities**:  \n",
    "   The model assigns probabilities ranging from $0.119$ to $0.924$ for each example.\n",
    "\n",
    "2. **Individual Losses**:  \n",
    "   Losses are higher for incorrect or uncertain predictions.\n",
    "\n",
    "3. **Total Cost**:  \n",
    "   The average loss across all examples is $J(\\vec{w}, b) = 0.350$.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Observations\n",
    "\n",
    "1. **Low Loss for Accurate Predictions**:  \n",
    "   - For $y = 0$, lower probabilities ($f_{\\vec{w}, b}(\\vec{x})$) result in small losses.\n",
    "   - For $y = 1$, higher probabilities ($f_{\\vec{w}, b}(\\vec{x})$) result in small losses.\n",
    "\n",
    "2. **High Loss for Incorrect or Uncertain Predictions**:  \n",
    "   - For $y = 1$, low predicted probabilities ($f_{\\vec{w}, b}(\\vec{x})$) result in high losses (e.g., Example 4).\n",
    "   - For $y = 0$, high predicted probabilities ($f_{\\vec{w}, b}(\\vec{x})$) result in high losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369956f8-f5d9-47ad-ad50-4d6b21c82511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
