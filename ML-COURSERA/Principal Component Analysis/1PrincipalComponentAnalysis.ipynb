{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef7a46da-62de-4cd6-bdea-2eaa4e1bdeba",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "This is an algorithm that is commonly used for visualization. Specifically, if you have a dataset with a lot of features, say 10 features or 50 features or even thousands of features, you can't plot 1,000 dimensional data. PCA, or principal components analysis is an algorithm that lets you take data with a lot of features, 50, 1,000, even more, and reduce the number of features to two features, maybe three features, so that you can plot it and visualize it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73829f7-0070-4efe-9532-2398166354c4",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "\n",
    "If we have a dataset with two features, $x_1$ and $x_2$. Initially, the data is plotted or represented using axes $x_1$ and $x_2$.   \n",
    "\n",
    "But if we want to replace these two features with just one feature. How can we choose a new axis, let's call it the z-axis, that is somehow a good feature for capturing, of representing the data?   \n",
    "\n",
    "Let's take a look at how PCA does this.  \n",
    "\n",
    "\n",
    "1. Pre-processing\n",
    "   - Zero Mean\n",
    "   - Feature Scaling\n",
    "2. Instead of using 2 axes to represent data. We only choose one. After that, we will project those points to the axis.\n",
    "   - Example 1 of choosing an axis: **Not to bad: Decently large variance** \n",
    "     <img src=\"./images/choose_an_axis.png\" width=\"500\">\n",
    "\n",
    "\n",
    "   - Example 2 of choosing an axis: **Bad: Too close, squished together** Capturing much less of the info from original data\n",
    "     <img src=\"./images/second-choosing-an-axis.png\" width=\"500\">\n",
    "  \n",
    "\n",
    "   - Example 3 of choosing an axis:  **Perfect Axis to capture Variation: Max Variance**\n",
    "     <img src=\"./images/perfect_axis.png\" width=\"500\">\n",
    "\n",
    "\n",
    "In the PCA algorithm, this axis is called the principal component. In the z-axis that when you project the data onto it, you end up with the largest possible amounts of variance. If you were to reduce the data to one axis or to one feature, this principal component is actually a good choice, and this is what PCA will do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1525b0a-494b-4666-8285-0aa85a87af61",
   "metadata": {},
   "source": [
    "## Deep Dive:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8ee04-374a-448e-80e7-63b9fdc03c99",
   "metadata": {},
   "source": [
    "We reduce the coordinate $(2, 3)$ by doing a dot product with a vector if unit length."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
